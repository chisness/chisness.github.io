## Intro
This tutorial is made with two target audiences in mind: (1) Those with an interest in poker who want to understand how AI poker agents are made and (2) Those with an interest in coding who want to better understand poker and code poker agents from scratch. 

## Table of Contents
[1. Background on Poker Rules and Definitions](#1-background-on-poker-rules-and-definitions)

[2. History of Solving Poker](#2-history-of-solving-poker)
[3. Game Theory -- Equilibrium, Regret, and More](#3-game-theory----equilibrium--regret--and-more)
[4. Solving Toy Poker Games from Normal Form to Extensive Form](#4-solving-toy-poker-games-from-normal-form-to-extensive-form)
[5. Trees in Games](#5-trees-in-games)
[6. Implementing Leduc Hold'em in Python](#6-implementing-leduc-hold-em-in-python)
[7. Counterfactual Regret Minimization](#7-counterfactual-regret-minimization)
[8. Game Abstractions](#8-game-abstractions)
[9. Agent Evaluation](#9-agent-evaluation)
[10. CFR Advances](#10-cfr-advances)
[11. Libratus and DeepStack -- Newest Poker Agents and Research](#11-libratus-and-deepstack----newest-poker-agents-and-research)
[12. AI vs. Humans](#12-ai-vs-humans)
[13. Multiplayer Games](#13-multiplayer-games)
[14. Other Games (Chess, Atari, Go, Starcraft, Hanabi)](#14-other-games--chess--atari--go--starcraft--hanabi-)
[15. What Can Humans Learn?](#15-what-can-humans-learn-)

## 1. Background on Poker Rules and Definitions
## 2. History of Solving Poker
## 3. Game Theory -- Equilibrium, Regret, and More
## 4. Solving Toy Poker Games from Normal Form to Extensive Form
## 5. Trees in Games
## 6. Implementing Leduc Hold'em in Python
## 7. Counterfactual Regret Minimization
## 8. Game Abstractions
## 9. Agent Evaluation
## 10. CFR Advances
## 11. Libratus and DeepStack -- Newest Poker Agents and Research
## 12. AI vs. Humans
## 13. Multiplayer Games
## 14. Other Games (Chess, Atari, Go, Starcraft, Hanabi)
## 15. What Can Humans Learn?

$$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$

$$
\frac{1}{2}
$$

